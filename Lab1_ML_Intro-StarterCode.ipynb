{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Introduction to Machine Learning with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn is an open source Python machine learning module. Using scikit-learn makes it easy to implement a variety of machine learning tasks including regression, classification, clustering, dimensionality reduction, model selection and data pre-processing. The full documentation for scikit-learn is located at https://scikit-learn.org/stable/. It contains numerous examples and detailed descriptions for each function (and its associated parameters). This notebook will give you a brief introduction on how to implement the basic machine learning pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are missing any of the packages, uncomment the line(s) below to install\n",
    "# %pip install sklearn\n",
    "# %pip install pandas\n",
    "# %pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading & Previewing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scikit-learn library contains a few small datasets that we can experiment with. Descriptions of the datasets are included here: https://scikit-learn.org/stable/datasets/toy_dataset.html. We will use two of them in this tutorial:\n",
    "\n",
    "1) The Boston house prices dataset (for regression tasks) and\n",
    "\n",
    "2) The breast cancer wisconsin (diagnostic) dataset (for classification tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load the datasets using helper functions and will take a look at the contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)\n",
    "(boston_X, boston_y) = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.DESCR)\n",
    "(cancer_X, cancer_y) = load_breast_cancer(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before interacting with our datasets any further, we must split the data into training and testing data. This way we can use the training data to explore the data and fit our models and then use the testing data to provide an unbiased measure of the performance of our models. This can be done using the train_test_split function in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 13)\n",
      "(127, 13)\n",
      "(379,)\n",
      "(127,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data with a 75%-25% training-test split\n",
    "# set the random state for reproducible results\n",
    "\n",
    "boston_X_train, boston_X_test, boston_y_train, boston_y_test = train_test_split(\n",
    "    boston_X, boston_y, test_size=0.25, random_state=671)\n",
    "# checks\n",
    "print(boston_X_train.shape)\n",
    "print(boston_X_test.shape)\n",
    "print(boston_y_train.shape)\n",
    "print(boston_y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE: split the breast cancer data with a train-test split of 70%-30% & random_state of 671 into:\n",
    "\n",
    "cancer_X_train, cancer_X_test, cancer_y_train, cancer_y_test = train_test_split(\n",
    "    cancer_X, cancer_y, test_size=0.3, random_state=671)\n",
    "\n",
    "# checks\n",
    "print(cancer_X_train.shape)\n",
    "print(cancer_X_test.shape)\n",
    "print(cancer_y_train.shape)\n",
    "print(cancer_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For almost all datasets, we will need to preprocess the data before we can fit any models. This may involve imputing missing data, scaling our features, applying one-hot encoding, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Imputing Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data is a very common problem across all datasets. One simple strategy for addressing it is to impute missing values using a chosen strategy such as the \"mean\", \"median\" or \"most_frequent\". First, let's check for missing data in our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "boston_X_train_df = pd.DataFrame(boston_X_train, columns=boston.feature_names)\n",
    "# check for which columns have missing values\n",
    "columns = boston_X_train_df.columns[boston_X_train_df.isnull().any()]\n",
    "print(len(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "cancer_X_train_df = pd.DataFrame(cancer_X_train, columns=cancer.feature_names)\n",
    "# check for which columns have missing values\n",
    "columns = cancer_X_train_df.columns[cancer_X_train_df.isnull().any()]\n",
    "print(len(columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As these are \"toy\" datasets, they do not have any missing values but let us still practice how we would impute missing values anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# impute using the 'mean' for the feature\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "# use fit_transform on training data\n",
    "boston_X_train_imp = imp.fit_transform(boston_X_train)\n",
    "# use transform on testing data\n",
    "boston_X_test_imp = imp.transform(boston_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the SimpleImputer with a 'median' strategy to the cancer data\n",
    "# As a result, you should have two variables:\n",
    "# (1) cancer_X_train_imp and\n",
    "# (2) cancer_X_test_imp\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# sometimes, missing_values ~= np.nan, may 0,999,-1....\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "# we fit and impute the trainX (fit_transform) and use same imputer to impute testX (tranform), just dont use info from testsata; also this is the reason we split first\n",
    "cancer_X_train_imp = imp.fit_transform(cancer_X_train)\n",
    "\n",
    "# 把traindata fit出来的median值impute到testdata，（当testdata不存在\n",
    "cancer_X_test_imp = imp.transform(cancer_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.  One-Hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the nature of our data and the ML models we want to implement, we may need to one-hot encode the categorical variables in our data as some models do not support categorical inputs. This means we will transform the feature into a set of dummy variables.\n",
    "\n",
    "Although we do not have any categorical variables in our cancer dataset, we do have a variable, 'RAD', in our boston dataset that we want to one-hot encode as it represents an index of accessibility to radial highways. We can do so using a OneHotEncoder and ColumnTransfer, which allows us to only apply the OneHotEncoder to only the 'RAD' column.\n",
    "\n",
    "First, let's implement the OneHotEncoder with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RAD', OneHotEncoder(), [8]), ('remainder', 'passthrough', [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12])]\n",
      "(379, 21)\n",
      "(127, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "rad_idx = list(boston.feature_names).index(\n",
    "    'RAD')  # find the index of the 'RAD' column = 8\n",
    "\n",
    "# passthrough specifies to keep other columns as they are\n",
    "enc_boston = ColumnTransformer(\n",
    "    [(\"RAD\", OneHotEncoder(), [rad_idx])], remainder=\"passthrough\")\n",
    "\n",
    "boston_X_train_enc = enc_boston.fit_transform(\n",
    "    boston_X_train_imp)  # use fit_transform on training data\n",
    "boston_X_test_enc = enc_boston.transform(\n",
    "    boston_X_test_imp)  # use transform on testing data\n",
    "\n",
    "print(enc_boston.transformers_)\n",
    "\n",
    "print(boston_X_train_enc.shape)\n",
    "print(boston_X_test_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that after applying the OneHotEncoder to the 'RAD' column, we have increased the number of columns in our dataset from 13 to 21 as it added one column for each unique value of 'RAD'. However, if we use this, we will run into the issue of multicollinearity since each dummy variable can be represented as a linear combination of the other dummy variables. To solve this issue, we want to create n-1 dummy variables. This can be done using the 'drop' parameter of the OneHotEncoder function, as shown below, resulting in one less column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RAD', OneHotEncoder(drop='first'), [8]), ('remainder', 'passthrough', [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12])]\n",
      "(379, 20)\n",
      "(127, 20)\n"
     ]
    }
   ],
   "source": [
    "# drop 1 to solve issue of multicollinearity\n",
    "\n",
    "enc_boston = ColumnTransformer(\n",
    "    [(\"RAD\", OneHotEncoder(drop='first'), [rad_idx])], remainder=\"passthrough\")\n",
    "boston_X_train_enc = enc_boston.fit_transform(boston_X_train_imp)\n",
    "boston_X_test_enc = enc_boston.transform(boston_X_test_imp)\n",
    "print(enc_boston.transformers_)\n",
    "\n",
    "print(boston_X_train_enc.shape)\n",
    "print(boston_X_test_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some machine learning models, we must first scale the features so that they are all on a shared scale. This supports faster model convergence and removes any bias toward features with higher magnitudes (i.e., giving more importance to features on a scale of cm vs. inches).\n",
    "\n",
    "\n",
    "Two of the most common techniques for feature normalization are 1) StandardScaler and 2) MinMaxScaler. StandardScaler works by adjusting the mean of each feature to zero with a standard deviation of 1. MinMaxScaler works by scaling all values to between 0 and 1. There are no hard rules for when to use one over the other but some factors to consider are the problem we intend to solve, assumptions regarding the distribution of the data (including the presence of outliers) and the ML models we plan on implementing. It can also be a good option to try out both and see which results in better performance. Either way, we must fit the scaler on our training data and then transform our testing data using it to avoid any data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "boston_X_train_scal = scaler.fit_transform(\n",
    "    boston_X_train_enc)  # use fit_transform on training data\n",
    "boston_X_test_scal = scaler.transform(\n",
    "    boston_X_test_enc)  # use transform on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# apply MinMaxScaler to the cancer dataset ('cancer_X_train_imp' and 'cancer_X_test_imp')\n",
    "# name the resulting variables 'cancer_X_train_scal' and 'cancer_X_test_scal'\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "cancer_X_train_scal = scaler.fit_transform(\n",
    "    cancer_X_train_imp)  # use fit_transform on training data\n",
    "cancer_X_test_scal = scaler.transform(\n",
    "    cancer_X_test_imp)  # use transform on testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have large datasets with high dimensionality, feature selection can help us reduce the dimensionality (e.g., the number of input variables or features) by removing irrelevant or redundant features. This can help with reducing the computational costs associated with training models and can also improve the performance of our models in some cases. There are many feature selection techniques so we will only experiment with a few here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (after applying Mutual Info): (379, 10)\n",
      "Testing data shape (after applying Mutual Info): (127, 10)\n",
      "Training shape (after applying PCA): (379, 12)\n",
      "Testing shape (after applying PCA): (127, 12)\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Mutual Information (regression)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "# select the top 10 features\n",
    "selector = SelectKBest(mutual_info_regression, k=10)\n",
    "boston_X_train_mi = selector.fit_transform(boston_X_train_scal, boston_y_train)\n",
    "print(\"Training data shape (after applying Mutual Info):\", boston_X_train_mi.shape)\n",
    "boston_X_test_mi = selector.transform(boston_X_test_scal)\n",
    "print(\"Testing data shape (after applying Mutual Info):\", boston_X_test_mi.shape)\n",
    "\n",
    "# Method 2: Principal component analysis (PCA)\n",
    "\n",
    "# can specify either the percent of explained variance or number of features\n",
    "pca = PCA(n_components=0.90)  # explaine 90% variance\n",
    "boston_X_train_pca = pca.fit_transform(boston_X_train_scal, boston_y_train)\n",
    "print(\"Training shape (after applying PCA):\", boston_X_train_pca.shape)\n",
    "boston_X_test_pca = pca.transform(boston_X_test_scal)\n",
    "print(\"Testing shape (after applying PCA):\", boston_X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape (after applying Mutual Info): (398, 15)\n",
      "Testing data shape (after applying Mutual Info): (171, 15)\n"
     ]
    }
   ],
   "source": [
    "# apply Mutual Information (classification) to the breast cancer data\n",
    "# select the top 15 features and name the resulting variables 'cancer_X_train_mi' & 'cancer_X_test_mi'\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Method 1: Mutual Information (regression)\n",
    "# select the top 15 features\n",
    "selector = SelectKBest(mutual_info_classif, k=15)\n",
    "\n",
    "cancer_X_train_mi = selector.fit_transform(cancer_X_train_scal, cancer_y_train)\n",
    "print(\"Training data shape (after applying Mutual Info):\", cancer_X_train_mi.shape)\n",
    "cancer_X_test_mi = selector.transform(cancer_X_test_scal)\n",
    "print(\"Testing data shape (after applying Mutual Info):\", cancer_X_test_mi.shape)\n",
    "\n",
    "# # Method 2: Principal component analysis (PCA)\n",
    "\n",
    "# # can specify either the percent of explained variance or number of features\n",
    "# pca = PCA(n_components=0.90)\n",
    "# cancer_X_train_pca = pca.fit_transform(cancer_X_train_scal, cancer_y_train)\n",
    "# print(\"Training shape (after applying PCA):\", cancer_X_train_pca.shape)\n",
    "# cancer_X_test_pca = pca.transform(cancer_X_test_scal)\n",
    "# print(\"Testing shape (after applying PCA):\", cancer_X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting, Cross-Validation & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally fit some models! scikit-learn allows you to easily implement a variety of models. We will work with a few of them here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by fitting two models - (1) Linear Regression and (2) K-Nearest Neighbors Regression - to our boston housing dataset. We will fit the models to each of the three feature sets - (1) all of the features (no feature selection), (2) the feature subset selected using mutual information and (3) the feature subset selected using PCA so that we can compare performance both between the models and the different feature subsets. We will use cross-validation (3 folds in this example) to get a more reliable estimate of the performance of our models without having to touch our test dataset yet. The default performance metric will be $R^2$, or the proportion of explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Validation use the data all from train dataset! not touch the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "                      R^2 on Fold 1  R^2 on Fold 2  R^2 on Fold 3  Mean R^2\n",
      "No Feature Selection       0.779718       0.626554       0.673468  0.693247\n",
      "MI Features                0.750709       0.670249       0.651748  0.690902\n",
      "PCA Features               0.805717       0.546609       0.622107  0.658144\n",
      "\n",
      "K-Nearest Neighbors Regression:\n",
      "                      R^2 on Fold 1  R^2 on Fold 2  R^2 on Fold 3  Mean R^2\n",
      "No Feature Selection       0.760128       0.543937       0.616316  0.640127\n",
      "MI Features                0.845605       0.792886       0.722900  0.787130\n",
      "PCA Features               0.769108       0.509425       0.582599  0.620377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr_scores_df = pd.DataFrame(\n",
    "    columns=[\"R^2 on Fold 1\", \"R^2 on Fold 2\", \"R^2 on Fold 3\", \"Mean R^2\"])\n",
    "print(\"Linear Regression:\")\n",
    "\n",
    "lr_scal_scores = list(cross_val_score(\n",
    "    lr, boston_X_train_scal, boston_y_train, cv=3))\n",
    "lr_scal_scores.append(np.mean(lr_scal_scores))\n",
    "lr_scores_df.loc[\"No Feature Selection\"] = lr_scal_scores\n",
    "\n",
    "lr_mi_scores = list(cross_val_score(\n",
    "    lr, boston_X_train_mi, boston_y_train, cv=3))\n",
    "lr_mi_scores.append(np.mean(lr_mi_scores))\n",
    "lr_scores_df.loc[\"MI Features\"] = lr_mi_scores\n",
    "\n",
    "lr_pca_scores = list(cross_val_score(\n",
    "    lr, boston_X_train_pca, boston_y_train, cv=3))\n",
    "lr_pca_scores.append(np.mean(lr_pca_scores))\n",
    "lr_scores_df.loc[\"PCA Features\"] = lr_pca_scores\n",
    "\n",
    "print(lr_scores_df.head())\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "knn_scores_df = pd.DataFrame(\n",
    "    columns=[\"R^2 on Fold 1\", \"R^2 on Fold 2\", \"R^2 on Fold 3\", \"Mean R^2\"])\n",
    "print(\"\\nK-Nearest Neighbors Regression:\")\n",
    "\n",
    "knn_scal_scores = list(cross_val_score(\n",
    "    knn, boston_X_train_scal, boston_y_train, cv=3))\n",
    "knn_scal_scores.append(np.mean(knn_scal_scores))\n",
    "knn_scores_df.loc[\"No Feature Selection\"] = knn_scal_scores\n",
    "\n",
    "knn_mi_scores = list(cross_val_score(\n",
    "    knn, boston_X_train_mi, boston_y_train, cv=3))\n",
    "knn_mi_scores.append(np.mean(knn_mi_scores))\n",
    "knn_scores_df.loc[\"MI Features\"] = knn_mi_scores\n",
    "\n",
    "knn_pca_scores = list(cross_val_score(\n",
    "    knn, boston_X_train_pca, boston_y_train, cv=3))\n",
    "knn_pca_scores.append(np.mean(knn_pca_scores))\n",
    "knn_scores_df.loc[\"PCA Features\"] = knn_pca_scores\n",
    "\n",
    "print(knn_scores_df.head())\n",
    "\n",
    "# to selct both the model and way of feature selection:\n",
    "# so we pick KNN - MI Features in this case， cause it has the highest R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, we see that linear regression performs similarily across the feature subsets but for KNN, we see that the model performs significantly better on the feature subset chosen using mutual information. Let's use GridSearchCV below to see if we can further improve its performance by adjusting the value of n_neighbors (the number of neighbors used)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_neighbors': 3}\n",
      "Best R^2 Score: 0.8166716460160099\n",
      "{'mean_fit_time': array([0.00050712, 0.        , 0.00049531, 0.0009985 , 0.00099754,\n",
      "       0.        , 0.0009973 ]), 'std_fit_time': array([5.48362732e-06, 0.00000000e+00, 4.95314598e-04, 4.76837158e-07,\n",
      "       2.38418579e-07, 0.00000000e+00, 0.00000000e+00]), 'mean_score_time': array([0.00049925, 0.00099719, 0.00124538, 0.00149477, 0.00099719,\n",
      "       0.00149548, 0.00099742]), 'std_score_time': array([4.99248505e-04, 3.57627869e-07, 2.48074532e-04, 4.97698784e-04,\n",
      "       1.19209290e-07, 4.98652458e-04, 1.19209290e-07]), 'param_n_neighbors': masked_array(data=[1, 2, 3, 4, 5, 6, 7],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 2}, {'n_neighbors': 3}, {'n_neighbors': 4}, {'n_neighbors': 5}, {'n_neighbors': 6}, {'n_neighbors': 7}], 'split0_test_score': array([0.82304336, 0.80160726, 0.82015593, 0.80868266, 0.80492277,\n",
      "       0.78887798, 0.7674301 ]), 'split1_test_score': array([0.77262725, 0.80728417, 0.81318736, 0.79076151, 0.77509845,\n",
      "       0.76237471, 0.74496636]), 'mean_test_score': array([0.7978353 , 0.80444571, 0.81667165, 0.79972208, 0.79001061,\n",
      "       0.77562634, 0.75619823]), 'std_test_score': array([0.02520806, 0.00283846, 0.00348429, 0.00896057, 0.01491216,\n",
      "       0.01325163, 0.01123187]), 'rank_test_score': array([4, 2, 1, 3, 5, 6, 7])}\n"
     ]
    }
   ],
   "source": [
    "# adjust k (hyperperemetrs\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# search over n_neighbors\n",
    "param_grid = [{'n_neighbors': [1, 2, 3, 4, 5, 6, 7]}]\n",
    "\n",
    "cv_knn = GridSearchCV(knn, param_grid, cv=2)\n",
    "cv_knn.fit(boston_X_train_mi, boston_y_train)\n",
    "print(\"Best Params:\", cv_knn.best_params_)\n",
    "print(\"Best R^2 Score:\", cv_knn.best_score_)\n",
    "print(cv_knn.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after selection, fitting and adjusting on train, now use the adjusted final model\n",
    "# to train and test on our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for regression tasks, evaulate use MSE, MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearchCV, we see that the the value of n_neighbors resulting in the best performance was 3. Let's use this as our final model and apply it to our test set. We will evaluate the test set using **Mean Squared Error (MSE) and Mean Absolute Error (MAE), two common measures of model performance for regression tasks**. The formula for MSE is:\n",
    "\n",
    "MSE = $\\frac{1}{n}\\sum_{i=1}^n(y_i - \\hat{y}_i )^2$ \n",
    "\n",
    "where $n$ is the number of data points, $y_i$ is the actual observation and $\\hat{y}_i$ is our prediction\n",
    "\n",
    "Similarly, the formula for MAE:\n",
    "\n",
    "MAE = $\\frac{1}{n}\\sum_{i=1}^n|(y_i - \\hat{y}_i )|$ \n",
    "\n",
    "where $n$ is the number of data points, $y_i$ is the actual observation and $\\hat{y}_i$ is our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2: 0.9391797935603915\n",
      "Testing R^2: 0.8423629972031058\n",
      "MSE: 12.876482939632547\n",
      "MAE: 2.750656167979003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "knn.fit(boston_X_train_mi, boston_y_train)\n",
    "preds = knn.predict(boston_X_test_mi)\n",
    "\n",
    "print(\"Training R^2:\", knn.score(boston_X_train_mi, boston_y_train))\n",
    "print(\"Testing R^2:\", knn.score(boston_X_test_mi, boston_y_test))\n",
    "print(\"MSE:\", mean_squared_error(boston_y_test, preds))\n",
    "print(\"MAE:\", mean_absolute_error(boston_y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Our testing score increased to 0.84! Now, let's move onto the breast cancer data, a classification task..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "              Fold 1 Accuracy  Fold 2 Accuracy  Fold 3 Accuracy  Mean Accuracy\n",
      "All Features         0.977444         0.954887         0.962121       0.964817\n",
      "MI Features          0.962406         0.939850         0.954545       0.952267\n",
      "\n",
      "K-Nearest Neighbors Classifier:\n",
      "              Fold 1 Accuracy  Fold 2 Accuracy  Fold 3 Accuracy  Mean Accuracy\n",
      "All Features         0.962406         0.969925         0.969697       0.967343\n",
      "MI Features          0.932331         0.932331         0.954545       0.939736\n"
     ]
    }
   ],
   "source": [
    "# cross validation for cancer data (classification\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf_scores_df = pd.DataFrame(\n",
    "    columns=[\"Fold 1 Accuracy\", \"Fold 2 Accuracy\", \"Fold 3 Accuracy\", \"Mean Accuracy\"])\n",
    "print(\"Random Forest Classifier:\")\n",
    "\n",
    "rf_scal_scores = list(cross_val_score(\n",
    "    rf, cancer_X_train_scal, cancer_y_train, cv=3))\n",
    "rf_scal_scores.append(np.mean(rf_scal_scores))\n",
    "rf_scores_df.loc[\"All Features\"] = rf_scal_scores\n",
    "\n",
    "rf_mi_scores = list(cross_val_score(\n",
    "    rf, cancer_X_train_mi, cancer_y_train, cv=3))\n",
    "rf_mi_scores.append(np.mean(rf_mi_scores))\n",
    "rf_scores_df.loc[\"MI Features\"] = rf_mi_scores\n",
    "\n",
    "print(rf_scores_df.head())\n",
    "\n",
    "\n",
    "# find another classifier and try!!!!!!!!!!!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_scores_df = pd.DataFrame(\n",
    "    columns=[\"Fold 1 Accuracy\", \"Fold 2 Accuracy\", \"Fold 3 Accuracy\", \"Mean Accuracy\"])\n",
    "print(\"\\nK-Nearest Neighbors Classifier:\")\n",
    "\n",
    "knn_scal_scores = list(cross_val_score(\n",
    "    knn, cancer_X_train_scal, cancer_y_train, cv=3))\n",
    "knn_scal_scores.append(np.mean(knn_scal_scores))\n",
    "knn_scores_df.loc[\"All Features\"] = knn_scal_scores\n",
    "\n",
    "knn_mi_scores = list(cross_val_score(\n",
    "    knn, cancer_X_train_mi, cancer_y_train, cv=3))\n",
    "knn_mi_scores.append(np.mean(knn_mi_scores))\n",
    "knn_scores_df.loc[\"MI Features\"] = knn_mi_scores\n",
    "\n",
    "\n",
    "print(knn_scores_df.head())\n",
    "\n",
    "# this accuracy is R2 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good example to show that feature selection will not always improve performance. This is why we must experiment with different methods and models to optimize them for the task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a lot of classification tasks: precision, recall and the f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a lot of classification tasks, we will want to focus our evaluation on precision, recall and the f1-score. The classification_report function in scikit-learn makes it easy to do so. As a review:\n",
    "\n",
    "\n",
    "Precision = $\\frac{TP}{TP + FP}$, or the fraction of our positive predictions that are actually positive instances\n",
    "\n",
    "Recall = $\\frac{TP}{TP + FN}$, or the fraction of positive instances that we actually predict as positive\n",
    "\n",
    "F1-score = $2*\\: \\frac{precision\\: *\\: recall}{precision + recall}$, or the harmonic mean of precision and recall\n",
    "- f1-score is basicaly: 考虑到预计错误的情况的“准确值”， 也是越大越好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        68\n",
      "           1       0.95      0.99      0.97       103\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.96      0.96       171\n",
      "weighted avg       0.97      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# using your chosen model, compute predictions for the test data\n",
    "# use these predictions to create the classification report\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(cancer_X_train_scal, cancer_y_train) # from crossva, we know all features are better than mi features\n",
    "preds = knn.predict(cancer_X_test_scal)\n",
    "print(classification_report(cancer_y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
